# Configuration for PPO Agent Trading 10Y Treasury Futures

project_name: "ReinforcementLearningAdaptiveTrading"
random_seed: 42

data:
  # Path to the raw data file (e.g., CSV of 10Y Treasury futures prices)
  # This might also include paths to other raw files like yield curve data if loaded separately.
  raw_data_path: "data/raw/10Y_futures_data.csv" # Example path
  yield_data_path: "data/raw/yield_curve_data.csv" # Example path for yields
  
  # Directory to save/load processed data (after cleaning, merging, feature engineering)
  processed_data_path: "data/processed/"
  train_processed_filename: "train_data_processed.csv"
  val_processed_filename: "validation_data_processed.csv"
  test_processed_filename: "test_data_processed.csv"
  
  # Scaler object path (if features are scaled and scaler is saved)
  scaler_path: "data/features/feature_scaler.joblib"

  # Date ranges for splitting the data
  train_period: 
    start: "2000-01-01"
    end: "2015-12-31"
  validation_period: # Used by EvalCallback during training
    start: "2014-01-01" # Example: last 2 years of the full training period
    end: "2015-12-31"
  test_period:
    start: "2016-01-01"
    end: "2023-12-31"

  # Name of the primary price column in the data
  price_column: "Close" # Or "price" depending on your CSV

  # List of feature column names that will be generated by feature_engineer.py
  # and expected by the TradingEnv
  feature_columns:
    - "yield_curve_slope"       # Example: 10Y_yield - 2Y_yield
    - "volatility_20d"          # Example: 20-day rolling std dev of returns
    - "ma_crossover_signal"     # Example: SMA(50) - SMA(200)
    - "momentum_1m"             # Example: 21-day price momentum
    - "rsi_14d"                 # Example: 14-day RSI
    # - "current_position"      # This is added by the environment if include_position_in_state is true

  # Parameters for feature engineering (can be nested if a feature has multiple params)
  feature_params:
    volatility_window: 20
    ma_short_window: 50
    ma_long_window: 200
    momentum_window_1m: 21 # ~1 month in trading days
    rsi_window: 14
    # For yield curve, specify column names if not standard in your raw data loader
    # long_term_yield_col_name: '10Y_Yield' 
    # short_term_yield_col_name: '2Y_Yield'
  
  # How to handle NaNs after feature engineering (rolling windows create NaNs at start)
  # 'ffill' then 'dropna' is common. 'dropna' alone if ffill isn't desired.
  feature_fillna_method: "ffill" 


environment_params:
  initial_capital: 1000000.0
  transaction_cost_bps: 0.5 # Basis points (0.5 bps = 0.00005)
  max_drawdown_pct: 0.20     # Max portfolio drawdown before episode termination (20%)
  stop_loss_penalty: -1.0    # Additional penalty when stop-loss is hit

  # Reward shaping coefficients
  reward_lambda_pnl: 1.0
  reward_lambda_volatility: 0.05 # Penalty factor for volatility
  reward_lambda_drawdown: 0.1   # Penalty factor for drawdown

  # If true, current agent position (encoded) is part of the observation space
  include_position_in_state: True
  # Max steps per episode. null means run through the whole dataset for that split.
  episode_max_steps: null 
  # For TradingEnv: observation window for price history, if features require it directly
  # This is distinct from feature engineering windows which are applied *before* data hits env.
  # If features like "past N returns" are NOT pre-calculated, env might need this.
  # For this project, features are pre-calculated, so env window_size might be 1 (just current step's features)
  # However, some designs pass recent raw prices to the env and it calculates some simple features.
  # Let's assume features are pre-calculated for now.
  # window_size: 1 # Days of price history for env state (if not using pre-calc features like rolling returns)


agent: # PPO Hyperparameters
  algorithm: "PPO"
  policy: "MlpPolicy" # Default SB3 MLP Policy
  n_envs: 4           # Number of parallel environments for make_vec_env

  learning_rate: 0.0003 # or 3e-4
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  # policy_kwargs: "{'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}]}" # Example: As string to be eval'd or directly structured if loader supports it


training:
  total_timesteps: 1000000 # 1 million
  verbose: 1
  seed: 42 # For reproducibility

  # Paths for saving models and logs
  save_path: "models/"
  log_path: "logs/" # For TensorBoard, eval results, and app logs
  
  tb_log_name: "PPO_TreasuryAgent" # TensorBoard log subdirectory name
  final_model_name: "ppo_treasury_final.zip"
  best_model_name: "ppo_treasury_best.zip" # Saved by EvalCallback
  vec_normalize_stats_name: "vec_normalize_treasury_stats.pkl"

  # Callbacks parameters
  checkpoint_save_freq: 100000 # Timesteps (total, will be divided by n_envs for actual save call freq)
  eval_freq: 50000             # Timesteps (total)
  eval_episodes: 5
  eval_deterministic: True

  # Environment normalization
  normalize_env: True # Whether to use VecNormalize

  # Early stopping (optional, configure if using an early stopping callback with EvalCallback)
  # early_stopping_patience: 10 # Number of evaluations with no improvement before stopping
  # early_stopping_metric: "eval/mean_reward" # Metric to monitor (e.g. from EvalCallback logs)
  # early_stopping_threshold: 0.001 # Minimum improvement to be considered significant


evaluation_params:
  # Default data split to use when running evaluate.py if not specified via CLI
  data_split_to_evaluate: "test"
  risk_free_rate: 0.01 # Annualized, for Sharpe ratio calculation (e.g., 1%)
  required_return_for_sortino: 0.0 # Annualized MAR for Sortino ratio

  baseline_strategies:
    - "buy_and_hold"
    - "ma_crossover"
    - "always_flat"
  
  ma_crossover_baseline: # Parameters for the MA crossover baseline strategy
    short_window: 50
    long_window: 200
  
  # Plotting options
  plot_save_path: "figures/" # Directory to save evaluation plots
  plot_equity_curves: True
  plot_prefix: "eval_results_" # Prefix for saved plot filenames


explainability_params:
  shap_nsamples: 100 # Number of samples for SHAP explainer background dataset
  shap_plot_path: "figures/" # Directory to save SHAP plots


logging: # Configuration for logger.py
  log_level: "INFO" # DEBUG, INFO, WARNING, ERROR, CRITICAL
  log_file: "logs/app_main.log" # Main application log file
  log_format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  log_date_format: "%Y-%m-%d %H:%M:%S"
